## Task1 赛题理解

天池比赛链接：**https://tianchi.aliyun.com/competition/entrance/531830/introduction**



##### 任务目标：

预测用户贷款是否违约

##### 任务类型：

分类

##### 数据规模：

总数据量120w，47列变量信息，其中15列为匿名变量

80万条作为训练集，20万条作为测试集A，20万条作为测试集B

##### 数据字段：

| 字段       | 描述 |
| :---------: | :---------: |
| id     |  为贷款清单分配的唯一信用证标识  | 
| loanAmnt   |  贷款金额  | 
| term |  贷款期限（year）  |
| interestRate | 贷款利率 |
| installment | 分期付款金额 |
| grade | 贷款等级 |
|subGrade|贷款等级之子级|
|employmentTitle|就业职称|
|employmentLength|就业年限（年）|
|homeOwnership|借款人在登记时提供的房屋所有权状况|
|annualIncome|年收入|
|verificationStatus|验证状态|
|issueDate|贷款发放的月份|
|purpose|借款人在贷款申请时的贷款用途类别|
|postCode|借款人在贷款申请中提供的邮政编码的前3位数字|
|regionCode|地区编码|
|dti|债务收入比|
|delinquency_2years|借款人过去2年信用档案中逾期30天以上的违约事件数|
|ficoRangeLow|借款人在贷款发放时的fico所属的下限范围|
|ficoRangeHigh|借款人在贷款发放时的fico所属的上限范围|
|openAcc|借款人信用档案中未结信用额度的数量|
|pubRec|贬损公共记录的数量|
|pubRecBankruptcies|公开记录清除的数量|
|revolBal|信贷周转余额合计|
|revolUtil|循环额度利用率，或借款人使用的相对于所有可用循环信贷的信贷金额|
|totalAcc|借款人信用档案中当前的信用额度总数|
|initialListStatus|贷款的初始列表状态|
|applicationType|表明贷款是个人申请还是与两个共同借款人的联合申请|
|earliesCreditLine|借款人最早报告的信用额度开立的月份|
|title|借款人提供的贷款名称|
|policyCode|公开可用的策略_代码=1新产品不公开可用的策略_代码=2|
|n系列匿名特征|匿名特征n0-n14，为一些贷款人行为计数特征的处理|

##### 评测标准
提交结果为每个测试样本是1的概率，也就是y为1的概率。评价方法为AUC评估模型效果（越大越好）。

##### 结果提交
提交前请确保预测结果的格式与sample_submit.csv中的格式一致，以及提交文件后缀名为csv。

形式如下：

```id,isDefault
800000,0.5
800001,0.5
800002,0.5
800003,0.5
```

##### 分类任务的常用评价指标：

- 混淆矩阵（Confuse Matrix）
- 准确率（Accuracy）
- 精确率（Precision）
- 召回率（Recall）
- F1 Score
- P-R曲线（Precision-Recall Curve）
- ROC
- AUC

###### 混淆矩阵

针对一个二分类问题，即将实例分成正类（positive）或负类（negative），在实际分类中会出现以下四种情况：
1. 若一个实例是正类，并且被预测为正类，即为真正类TP(True Positive )
2. 若一个实例是正类，但是被预测为负类，即为假负类FN(False Negative )
3. 若一个实例是负类，但是被预测为正类，即为假正类FP(False Positive )
4. 若一个实例是负类，并且被预测为负类，即为真负类TN(True Negative )

###### 准确率（Accuracy）、精确率（Precision）、召回率（Recall）、F1 Score

1. 准确率(Accuracy)
预测正确的样本数量占总量的百分比，具体的公式如下：


$$Accuracy = \frac{TP + TN}{TP+FN+FP+TN} \$$


准确率有一个缺点，就是数据的样本不均衡，这个指标是不能评价模型的性能优劣的。

假如一个测试集有正样本99个，负样本1个。模型把所有的样本都预测为正样本，那么模型的Accuracy为99%，看评价指标，模型的效果很好，但实际上模型没有任何预测能力。

2. 精准率(Precision)
又称为查准率，是针对预测结果而言的一个评价指标。在模型预测为正样本的结果中，真正是正样本所占的百分比，具体公式如下：

$$Precision = \frac{TP}{TP+FP} \$$

精准率的含义就是在预测为正样本的结果中，有多少是准确的。这个指标比较谨慎，分类阈值较高。

3. 召回率(Recall)
又称为查全率，是针对原始样本而言的一个评价指标。在实际为正样本中，被预测为正样本所占的百分比。具体公式如下：

$$Recall = \frac{TP}{TP+FN} \$$

尽量检测数据，不遗漏数据，所谓的宁肯错杀一千，不肯放过一个，分类阈值较低。

4. F1 Score
针对精准率和召回率都有其自己的缺点；如果阈值较高，那么精准率会高，但是会漏掉很多数据；如果阈值较低，召回率高，但是预测的会很不准确。

$$F1 = \frac{2*P*R}{P+R} \$$

5. P-R曲线

P-R曲线是描述精确率和召回率变化的曲线。对于所有的正样本，

绘制P-R曲线？

设置不同的阈值，模型预测所有的正样本，计算对应的精准率和召回率。


模型与坐标轴围成的面积越大，则模型的性能越好。但一般来说，曲线下的面积是很难进行估算的，所以衍生出了“平衡点”（Break-Event Point，简称BEP），即当P=R时的取值，平衡点的取值越高，性能更优。

6. ROC曲线和AUC
##### ROC

ROC（Receiver Operating Characteristic）曲线，又称接受者操作特征曲线。曲线对应的纵坐标是TPR，横坐标是FPR。


绘制方法：

设置不同的阈值，会得到不同的TPR和FPR，而随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着负类，即TPR和FPR会同时增大。阈值最大时，对应坐标点为（0,0），阈值最小时，对应坐标点（1,1）。

理想目标： TPR=1, FPR=0，即图中(0,1)点。故ROC曲线越靠拢(0,1)点，即，越偏离45度对角线越好。对应的就是TPR越大越好，FPR越小越好。

##### AUC

AUC(Area Under Curve)是处于ROC曲线下方的那部分面积的大小。AUC越大，代表模型的性能越好。

对于例子三的样本不均衡，对应的TPR=1，而FPR=1，能够判断模型性能不好。

